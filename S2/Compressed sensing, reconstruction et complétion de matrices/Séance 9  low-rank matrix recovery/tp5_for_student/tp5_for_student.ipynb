{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical work 5: matrix completion for inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load nt_toolbox\n",
    "import sys\n",
    "#sys.path.append('../tp1/')\n",
    "from nt_toolbox.general import rescale\n",
    "from nt_toolbox.signal import load_image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image(im, title=\"\"):\n",
    "    \"\"\"Display an image im (2D array-like) with a title.\n",
    "    \"\"\"\n",
    "    plt.imshow(im, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    ">I. [Low-rank matrices](#I.-Low-rank-matrices)\n",
    "\n",
    ">II. [Image reconstruction](#II.-Image-reconstruction)\n",
    "\n",
    ">1. [Masked image](#1.-Masked-image)\n",
    "1. [Nuclear norm minimization](#2.-Nuclear-norm-minimization)\n",
    "\n",
    "> III. [Proximal methods](#III.-Proximal-methods)\n",
    "1. [Exact problem](#1.-Exact-problem)\n",
    "1. [Regularized problem](#2.-Regularized-problem)\n",
    "\n",
    "> IV. [Stability to permutation](#IV.-Stability to permutation)\n",
    "\n",
    "> V. [Evaluation of the coherence](#Evaluation of the coherence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Low-rank matrices\n",
    ">This part is aimed at demonstrating that real-world images benefit from an inherent sparsity, that is of a different kind than Fourier/Wavelet sparsity.\n",
    "For this purpose, let us load and display an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = rescale(load_image(\"ryan_lalaland.bmp\")) # Load the image with prescribed size\n",
    "show_image(im, 'Original image')  # Display the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Question 1.**\n",
    "Plot together the $n$ singular values $(\\sigma_i)_{1 \\le i \\le n}$ of the image ($\\sigma_{(1)} \\ge \\dots \\ge  \\sigma_{(n)}$) and the ratio of inertia $\\sum_{i=1}^m \\sigma_{(i)}/\\sum_{i=1}^n \\sigma_{(i)}$ as a function of the ratio of singular values $\\frac mn$.\n",
    "\n",
    ">What can you say about image sparsity / rank ? How many singular values do you need to get 80% of the information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Question 2.**\n",
    "Given that an approximation of the image can be obtained by setting the smallest singular values to $0$, display several approximations for different ratio of singular values (ranging from $0$ to $20\\%$) / inertia (ranging from $50\\%$ to $100\\%$).\n",
    "You may need functions *trunc_r(im, ratio)* and *trunc_i(im, inertia)* that compute an approximation of the image *im* given a ratio of singular values or of inertia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Approximation with respect to the ratio of singular values.\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, r in enumerate(np.linspace(0, 0.2, num=16)):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    show_image(trunc_r(im, r), 'Ratio: {0:0.2f}%'.format(100*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Approximation with respect to the inerta ratio.\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, r in enumerate(np.linspace(0.5, 1, num=16)):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    show_image(trunc_i(im, r), 'Inertia: {0:0.2f}%'.format(100*r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Image reconstruction\n",
    "### 1. Masked image\n",
    ">In image reconstruction (also known as image inpainting or matrix completion), we observe an image with missing values.\n",
    "In practice, given an image $I \\in \\mathbb R^{n_1 \\times n_2}$, we consider being provided with a mask $O \\in \\mathbb R^{n_1 \\times n_2}$, such that each entry of $O$ equals $1$ if we observe a pixel and $0$ otherwise.\n",
    "Therefore, if we consider that missing data is set to $0$, we observe $O \\odot I$, where $\\odot$ is the pointwise product.\n",
    "\n",
    ">This is what is done in the following script, where the image is first made explicitely low-rank (by truncation of its singular values) and masked.\n",
    "In this function, *ratio* is the ratio of singular values kept unscathed, and *prop* is the proportion of observed pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(im, ratio=0.1, prop=0.2):\n",
    "    im_trunc = trunc_r(im, ratio)  # Approximation by truncation\n",
    "    mat_mask = np.random.binomial(1, prop, size=im.shape)  # Random mask (iid Bernoulli variables)\n",
    "    return im_trunc, mat_mask\n",
    "\n",
    "im_trunc, mat_mask = mask(im, ratio=0.2, prop=0.4)  # Approximate image and mask matrix\n",
    "im_masked = im_trunc * mat_mask  # Observed image\n",
    "\n",
    "for p, (i, t) in enumerate([(im, 'Original image'),\n",
    "                           (im_trunc, 'Truncated image'),\n",
    "                           (im_masked, 'Masked image')]):\n",
    "    plt.subplot(1, 3, p+1)\n",
    "    show_image(i, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Nuclear norm minimization\n",
    ">Let $I \\in \\mathbb R ^{n_1 \\times n_2}$ be the orginal image, $O \\in \\mathbb R ^{n_1 \\times n_2}$ be mask of observed pixels and $M \\colon \\mathbb R ^{n_1 \\times n_2} \\to \\mathbb R ^{n_1 \\times n_2}$ be the mask operator, such that $MX = O \\odot X$.\n",
    "\n",
    ">We aim at solving the nuclear norm minimization problem:\n",
    "$$\n",
    "    \\begin{array}{cl}\n",
    "        \\displaystyle{ \\operatorname{minimize}_{X \\in \\mathbb R ^{n_1 \\times n_2}} }\n",
    "        & \\displaystyle{ \\|X\\|_{S_1} } \\\\\n",
    "        \\operatorname{st}\n",
    "        & \\displaystyle{ MX = MI.}\n",
    "    \\end{array}\n",
    "$$\n",
    "\n",
    ">*cvxpy* is a user-friendly interface that helps solving such a problem (in practice, it calls solvers such as *cvxopt*).\n",
    "\n",
    ">**Question 1.**\n",
    "There are two mistakes in the following script.\n",
    "Fix them and compare the image reconstructed by filling the average value and by nuclear norm minimization.\n",
    "What do you feel about them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy\n",
    "\n",
    "def mat_compl_py(im_trunc, mat_mask):\n",
    "    im_masked = im_trunc * mat_mask  # Observed image\n",
    "    n1, n2 = im_masked.shape  # Image size\n",
    "\n",
    "    X = cvxpy.Variable((n1, n2))  # Optimization variable\n",
    "    obj = cvxpy.Minimize(cvxpy.norm(X, 'fro'))  # Objective function\n",
    "    constraints = [cvxpy.multiply(mat_mask, X) == im_masked]  # Constraint\n",
    "\n",
    "    prob = cvxpy.Problem(obj, constraints)  # Optimization problem\n",
    "    prob.solve(solver=cvxpy.SCS)  # Solve the problem\n",
    "    \n",
    "    if prob.status != 'optimal':\n",
    "        print('CVXPY failed to reach optimal value.')\n",
    "    else:\n",
    "        im_rec = np.asarray(X.value)  # Solution = reconstructed image\n",
    "        \n",
    "        # Average filling: fill missing pixels with mean of observed pixels\n",
    "        im_fill = im_masked.copy()\n",
    "        im_fill[np.where(mat_mask == 0)] = im_masked[np.where(mat_mask == 1)].max()\n",
    "        \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for p, (i, t) in enumerate([(im_trunc, 'Truncated image'),\n",
    "                                    (im_masked, 'Masked image'),\n",
    "                                    (im_fill, 'Average filling'),\n",
    "                                    (im_rec, 'Reconstructed image')]):\n",
    "            plt.subplot(1, 4, p+1)\n",
    "            show_image(i, t)\n",
    "            \n",
    "        return im_fill, im_rec\n",
    "            \n",
    "im_fill, im_rec = mat_compl_py(im_trunc, mat_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Question 2.**\n",
    "Plot the histogram of recovered pixels for both reconstruction techniques. Compare with the histogram of original pixels.\n",
    "What can you say?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Question 3.**\n",
    "Create an image that is sparse and low-rank. \n",
    "\n",
    ">Mask the image and apply the reconstruction. What can you conclude ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "sparse and low-rank images are difficult to reconstruct.\n",
    "This is known from theory since matrice completion works well only when the singular vectors (of the image to be reconstructed) are incoherent with the canonical basis.\n",
    "This is not the case here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Proximal methods\n",
    "### 1. Exact problem\n",
    ">We aim here at solving the problem of matrix completion:\n",
    "$$\n",
    "    \\operatorname{minimize}_{X \\in \\mathbb R ^{n_1 \\times n_2}}\n",
    "    \\|X\\|_{S_1} + \\chi_{\\mathcal A}(X),\n",
    "$$\n",
    "where $\\mathcal A = \\{X \\in \\mathbb R^{n_1 \\times n_2} : MX = MI\\}$.\n",
    "\n",
    ">** Question 1.**\n",
    "Knowing that $\\operatorname{prox}_{\\gamma \\|\\cdot\\|_{S_1}}$ is the soft-thresholding operator on the singular values, i.e. $\\operatorname{prox}_{\\gamma \\|\\cdot\\|_{S_1}}(X) = US_\\gamma V$ where $X = USV$ is the singular value decomposition of $X$ and $S_\\gamma$ is the diagional matrix with entries $(\\max(0, S_{kk}-\\gamma))_k$, provide a function *proxS1(x, gamma)* that computes $\\operatorname{prox}_{\\gamma \\|\\cdot\\|_{S_1}}(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">** Question 2.**\n",
    "Show that $\\operatorname{prox}_{\\chi_{\\mathcal A}}(X) = X - M(X - I)$.\n",
    "\n",
    "\n",
    "\n",
    ">** Question 3.**\n",
    "Define a function *DRmethod(im_masked, mat_mask, n_it=100, version=1)* that implements the Douglas-Rachford method with $f = \\|\\cdot\\|_{S_1}$ and $g = \\chi_{\\mathcal A}$, and conversely with $f = \\chi_{\\mathcal A}$ and $g = \\|\\cdot\\|_{S_1}$.\n",
    "This function has to return an approximate solution and the sequence $(\\|X_k\\|_{S_1})_k$.\n",
    "\n",
    ">Compare both versions, the behavior of the objective value and the error $\\|MX-MI\\|_F$.\n",
    "Which one is preferable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Regularized problem\n",
    ">In this section, we decide to approximate the linear constraint with a regularization.\n",
    "Therefore, we aim at solving:\n",
    "$$\n",
    "    \\operatorname{minimize}_{X \\in \\mathbb R ^{n_1 \\times n_2}}\n",
    "    \\|X\\|_{S_1} + \\frac{\\mu}{2} \\|MX - MI\\|_F^2,\n",
    "$$\n",
    "where $\\mu > 0$.\n",
    "\n",
    ">**Question 2.**\n",
    "Define a function *fista(im_masked, mat_mask, mu=1., n_it=100)*, that:\n",
    "- performs an accelerated proximal gradient descent with fixed step size;\n",
    "- terminates after n_it iterations;\n",
    "- returns an approximate solution $X$ and the sequence of objective values $(\\|X_k\\|_{S_1} + \\frac{\\mu}{2} \\|MX_k - MI\\|_F^2)_k$.\n",
    "\n",
    ">Run this function to recover the original image.\n",
    "Plot the image, the objective function and compute the error $\\|MX - MI\\|_F$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## IV. Stability to permutation\n",
    "\n",
    "In this section, we propose to fix some mask $O$ and\n",
    "1. to perform the low-rank recovery reconstruction of an image 'im', called 'im_rec', then \n",
    "+ to permute the columns of 'im' and call the resulting image 'im_flip'\n",
    "+ to perform the low-rank recovery reconstruction of 'im_flip', called 'im_rec_flip', then \n",
    "+ to unflip the columns of 'im_rec_flip' and to compare to 'im_rec'.\n",
    "\n",
    "\n",
    "To your opinion, what is the expected result to this experiment? Once your prediction made, launch the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial image\n",
    "im_trunc, mat_mask = mask(im, ratio=0.2, prop=0.4)  # Approximate image and mask matrix\n",
    "im_masked = im_trunc * mat_mask  # Observed image\n",
    "show_image(im_trunc, 'Original image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip reconstruction + Unflipping\n",
    "from toolbox.flip import low_rank_recovery_flip_test_columns\n",
    "\n",
    "im_rec_flip_unflipped = low_rank_recovery_flip_test_columns(im_masked, mat_mask, n_it=100)\n",
    "show_image(im_rec_flip_unflipped , 'Unflipped reconstructed image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Evaluation of the coherence\n",
    "\n",
    "During Lecture \\# 9, we introduced the notion of coherence for the matrix completion problem. When observed entries of a matrix $X\\in \\mathbb{R}^{n_1 \\times n_2}$ are uniformly drawn, the coherence $\\mu(X)$ is the smallest number such that\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "    \\max_{1\\leq i \\leq n_1} \\frac{n_1}{r} \\| P_{col(X)} e_i \\|_2^2 &\\leq \\mu(X) \\\\\n",
    "    \\max_{1\\leq i \\leq n_2} \\frac{n_2}{r} \\| P_{row(X)} e_i \\|_2^2 &\\leq \\mu(X) \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "where $P_{col(X)}$ and $P_{row(X)}$ are the projection onto the column space and row space of $X$ (resp. subsets of $\\mathbb{R}^{n_1}$ and $\\mathbb{R}^{n_2}$). Set $X=UDV^T$ to be a SVD of $X$.  If $X$ is of rank $r$, one can write that \n",
    "$$\n",
    "X= U^{(r)} D^{(r)} (V^{(r)})^T,\n",
    "$$\n",
    "where $U^{(r)} \\in \\mathbb{R}^{n_1\\times r}$, $D^{(r)}\\in \\mathbb{R}^{r\\times r}$ and $ V^{(r)} \\in \\mathbb{R}^{n_2\\times r}$, and where $U^{(r)}$ and $V^{(r)}$ have orthogonal columns that contain\n",
    "the left and right singular vectors.\n",
    "\n",
    "The orthogonal projection matrix onto the column\n",
    "space of $X$ is then\n",
    "$$\n",
    "P_{col(X)} = U^{(r)} (U^{(r)})^T \\in \\mathbb{R}^{n_1 \\times n_1},\n",
    "$$\n",
    "and on the row space of $X$\n",
    "$$\n",
    "P_{row(X)} = V^{(r)} (V^{(r)})^T \\in \\mathbb{R}^{n_2 \\times n_2},\n",
    "$$\n",
    "\n",
    "1. Evaluate the coherence parameter for the truncated image where the first 20\\% singular values are kept.\n",
    "+ Conclude on the chance of recovery using matrix completion technique for such an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coherence is really high here, which in theory prescribes for matrix completion with a low number of measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
