{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Introduction to machine learning\n", "\n", "*Maxime Sangnier*\n", "\n", "Fall, 2022\n", "\n", "## Practical session 1: discriminant analysis, logistic regression and boosting"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Table of contents\n", "1. [Discriminant analysis](#part1)\n", "    - [Linear discriminant analysis](#part1sec1)\n", "    - [Quadratic discriminant analysis](#part1sec2)\n", "    - [Fisher discriminant analysis](#part1sec3)\n", "1. [Logistic regression](#part2)\n", "1. [Adaboost](#part3)\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "Packages:\n", "\tnympy as np\n", "\tmatplotlib.pyplot as plt\n", "\tseaborn as sns\n", "\n", "Functions:\n", "\tplotXY\n", "\tplot_frontiere\n", "\tmap_regions\n", "\tcovariance\n", "\tplot_cov\n", "\tsample_gmm\n", "\tscatter\n", "\tplot_level_set\n", "\tgaussian_sample\n", "\n"]}], "source": ["from mllab import *"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Discriminant analysis <a id=\"part1\"></a>\n", "## Linear discriminant analysis <a id=\"part1sec1\"></a>\n", ">The `covariance` function makes it possible to build a $2 \\times 2$ covariance matrix based on spreads $\\sigma_1$ and $\\sigma_2$, and the angle $\\theta$."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"data": {"text/plain": ["\u001b[0;31mSignature:\u001b[0m \u001b[0mcovariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mDocstring:\u001b[0m Covariance matrix with eigenvalues sigma1 and sigma2, rotated by the angle theta.\n", "\u001b[0;31mFile:\u001b[0m      ~/bitbucket/class/2017/5MS102_Apprentissage_non-supervis\u00e9/nb/m2/mllab.py\n", "\u001b[0;31mType:\u001b[0m      function\n"]}, "metadata": {}, "output_type": "display_data"}], "source": ["covariance?"]}, {"cell_type": "markdown", "metadata": {}, "source": [">Based on the Cholesky decomposition of a $2 \\times 2$ covariance matrix $\\Sigma$, write a function that generates a multivariate Gaussian $n$-sample of mean $\\mu \\in \\mathbb R^2$ and covariance $\\Sigma$.\n", "The corresponding numpy array should be of size $(n, 2)$.\n", "\n", ">Compute the mean and the empirical covariance of the sample using Numpy routines."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Answer"], "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": [">Generate two multivariate Gaussian samples of size $n_1 = n_2 = 50$ with different means and equal covariance matrices.\n", "Plot both samples with different markers by using the function `plotXY`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Answer"], "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": [">Based on the following code, implement a linear discriminant classifier, taking as parameters an $n \\times 2$ Numpy array as data and a size-$n$ array of labels."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Answer\n", "from sklearn.base import BaseEstimator\n", "from sklearn.discriminant_analysis import LinearClassifierMixin\n", "\n", "class LDA(BaseEstimator, LinearClassifierMixin):\n", "    \"\"\"\n", "        LDA classifier for two classes.\n", "    \"\"\"\n", "    def __init__(self, prior=None):\n", "        \"\"\"\n", "            prior: wether to use prior in the intercept. Default is false.\n", "        \"\"\"\n", "        self.prior = prior\n", "        \n", "    def fit(self, X, y):\n", "        # Estimate covariance matrix and means\n", "        # Todo\n", "\n", "        # End todo\n", "        if not self.prior:\n", "            pi1, pi2 = 0.5, 0.5\n", "        else:\n", "            pi1, pi2 = np.mean(y == y.max()), np.mean(y == y.min())\n", "        # Compute direction and intercept\n", "        # Todo\n", "\n", "        # End todo\n", "        return self\n", "\n", "    def decision_function(self, X):\n", "        # Compute decisions\n", "        # Todo\n", "\n", "        # End todo\n", "        return decisions\n", "\n", "    def predict(self, X):\n", "        # Compute predictions\n", "        # Todo\n", "\n", "        # End todo\n", "        return predictions"], "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": [">Create the Numpy arrays `X` and `y` based on the samples generated previously and fit a linear discriminant classifier.\n", "Plot the data along with the classifier frontiere (use the function `plot_frontiere`)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Answer"], "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": [">Compare the result of [scikit-learn LDA](http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis) (decision function and frontiere)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Answer"], "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Quadratic discriminant analysis <a id=\"part1sec2\"></a>\n", ">Analyze the behavior of LDA and [QDA](http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis) when it is faced to anisotropic Gaussian samples (in particular, check if the frontiere is the bisector of the line segment for which the extremities are both class centers), and then to Gaussian samples with different covariance matrices (you can use `plot_frontiere` with a list of classifiers)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Answer\n", "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n", "\n", "qda = QuadraticDiscriminantAnalysis()\n", "\n", "# Gassian parameters\n", "mu1 = mu = [0, 0]\n", "mu2 = [5, 3]\n", "\n", "plt.figure(figsize=(10, 20))\n", "for (p1, p2) in [((1, 1, 0), ) * 2,\n", "                  ((1, 5, 0), ) * 2,\n", "                  ((1, 5, np.pi/6), ) * 2,\n", "                  ((1, 5, 0), (5, 1, 0)),\n", "                  ((1, 5, 0), (5, 1, np.pi/3))]:\n", "    # Dataset\n", "    # Todo\n", "\n", "    # End todo\n", "    \n", "    # Discriminant analysis\n", "    # Todo\n", "\n", "    # End todo\n", "    \n", "    # Class means\n", "    # Todo\n", "\n", "    # End todo\n", "    \n", "    # Plot frontieres and class means\n", "    # Todo\n", "\n", "    # End todo"], "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Fisher discriminant analysis <a id=\"part1sec3\"></a>\n", ">Implement the Fisher discriminant analysis based on the following code.\n", "In practice, what is the difference between LDA and FisherDA?"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["class FisherDA(BaseEstimator, LinearClassifierMixin):\n", "    \"\"\"\n", "        Fisher discriminant analysis for two classes.\n", "    \"\"\"\n", "    def fit(self, X, y):\n", "        pass\n", "\n", "    def decision_function(self, X):\n", "        pass\n", "\n", "    def predict(self, X):\n", "        pass"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Answer\n", "class FisherDA(BaseEstimator, LinearClassifierMixin):\n", "    \"\"\"\n", "        Fisher discriminant analysis for two classes.\n", "    \"\"\"\n", "    def fit(self, X, y):\n", "        # Estimate prior, covariance matrix and means\n", "        # To do\n", "\n", "        # End todo\n", "        \n", "        # Compute direction and intercept\n", "        # Todo\n", "\n", "        # End todo\n", "        return self\n", "\n", "    def decision_function(self, X):\n", "        # Compute decisions\n", "        # Todo\n", "\n", "        # End todo\n", "        return decisions\n", "\n", "    def predict(self, X):\n", "        # Compute predictions\n", "        # Todo\n", "\n", "        # End todo\n", "        return predictions"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Answer"], "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["# Logistic regression <a id=\"part2\"></a>\n", ">We consider that $X|Y=1 \\sim \\mathcal N(0, I)$ and $X|Y=-1 \\sim 0.5 \\mathcal N\\left(\\begin{pmatrix} 5 \\\\ 3 \\end{pmatrix}, I\\right) + 0.5 \\mathcal N\\left(\\begin{pmatrix} 8 \\\\ 9 \\end{pmatrix}, I\\right)$ (non-Gaussian class).\n", "Compare LDA and [logistic regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Answer"], "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": [">What about with this dataset (class $-1$ is Gaussian but with an outlier)?"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["# Dataset\n", "X1 = gaussian_sample(mu=[0, 0])\n", "X2 = gaussian_sample(mu=[5, 3], n=49)\n", "X3 = gaussian_sample(mu=[20, 20], n=1).reshape(1, -1)\n", "\n", "X = np.r_[X1, X2, X3]\n", "Y = np.r_[np.ones(X1.shape[0]), -np.ones(X2.shape[0]), -np.ones(X3.shape[0])]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Answer"], "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["# Adaboost <a id=\"part3\"></a>\n", ">We consider the dataset defined below."]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["# Dataset\n", "X1 = gaussian_sample(mu=[0, 0], sigma1=10, theta=np.pi/6)\n", "X2 = gaussian_sample(mu=[5, 3], sigma1=3, sigma2=10, theta=np.pi/6, n=50)\n", "X3 = gaussian_sample(mu=[-5, -2], sigma1=3, sigma2=10, theta=np.pi/10, n=50)\n", "\n", "X = np.r_[X1, X2, X3]\n", "Y = np.r_[np.ones(X1.shape[0]), -np.ones(X2.shape[0]), -np.ones(X3.shape[0])]"]}, {"cell_type": "markdown", "metadata": {}, "source": [">Fit an [Adaboost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) classifier with $100$ weak learners and the algorithm SAMME.\n", "Map the classifier regions on a figure."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Answer"], "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": [">Plot on a new figure the estimator errors (attribute `estimator_errors_`).\n", "What do you observe?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Answer"], "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": [">Load the [dataset digits](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits).\n", "How many observations, covariates and classes has it?\n", "[Split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) the dataset into two equally sized subsets (one for training, the other for testin, i.e. estimating the true error)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Answer"], "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": [">Plot the train and test errors of both algorithms SAMME and SAMME.R with respect to the number of iterations (from 1 to 200) for the dataset digits.\n", "For this purpose, use [`DecisionTreeClassifier(max_depth=5)`](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) as base learner."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Answer"], "outputs": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.4"}}, "nbformat": 4, "nbformat_minor": 4}