{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwUwrL3Vs6YA"
   },
   "source": [
    "## <font color=darkcyan> MCMC algorithms</font>\n",
    "$\n",
    "\\newcommand{\\PP}{\\mathbb P}\n",
    "\\newcommand{\\PE}{\\mathbb E}\n",
    "\\newcommand{\\Xset}{\\mathsf{X}}\n",
    "\\newcommand{\\nset}{\\mathbb{N}}\n",
    "\\newcommand{\\invcdf}[1]{F_{#1}^{\\leftarrow}}\n",
    "\\newcommand{\\rmd}{\\mathrm{d}}\n",
    "\\newcommand{\\rme}{\\mathrm{e}}\n",
    "$\n",
    "In this notebook, we illustrate some results of the course **Simulation methods for generative models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yym8_tdfT3nu"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import expon, geom, norm\n",
    "from math import pi\n",
    "from pylab import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0uyG-Ta11yX"
   },
   "source": [
    "#### <font color=darkorange> The invariant measure of a Markov chain </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GKS4wzw-e2w"
   },
   "source": [
    "\n",
    "#### First example (see Exercise 7.4)\n",
    "\n",
    "\n",
    "\n",
    "Consider a Gaussian AR($1$) process, $X_t= \\mu + \\phi X_{t-1} + \\sigma Z_t$, where $(Z_t)_{t \\in \\nset}$ is an iid sequence of standard Gaussian random variables, independent of $X_0$. Assume that $|\\phi| < 1$. Then, the Gaussian distribution with mean $\\mu/(1-\\phi)$ and variance $\\sigma^2/(1-\\phi^2)$ is a stationary distribution of the Markov chain. We check this property with an histogram of the values taken by a single trajectory of the Markov chain. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "tcBNLyCn_VYn",
    "outputId": "e332598e-991d-499e-eb15-108075955734"
   },
   "outputs": [],
   "source": [
    "p,mu,phi,sig=10000,1,0.9,1\n",
    "mc=npr.rand(1)*np.ones(p)\n",
    "f=lambda x,m,sq: np.exp(-(x-m)**2/(2*sq))/np.sqrt(2*pi*sq)\n",
    "mc[0]=0\n",
    "for i in range(p-1):\n",
    "    mc[i+1]=mu+phi*mc[i]+sig*npr.randn()\n",
    "x=np.linspace(min(mc),max(mc),30)\n",
    "plt.hist(mc,bins=80,density=True,edgecolor=\"black\")\n",
    "plt.plot(x,f(x,mu/(1-phi),sig**2/(1-phi**2)),color=\"red\")\n",
    "plt.title(\"Histogram of a trajectory of the MC. n=\"+str(p))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9gPqgbgtJoJ"
   },
   "source": [
    "\n",
    "\n",
    "#### Second example (Exercise 7.5)\n",
    "\n",
    "We here consider an example of a Markov chain (given during Tutorial 1) whose state space $\\Xset= (0,1)$ is the open unit interval.\n",
    "If the chain is at $x$, it picks one of the two intervals $(0,\\ x)$ or $(x,\\ 1)$ with equal probability $1/2$, and then moves to a point $y$ which is uniformly distributed in the chosen interval. The invariant distribution of the Markov chain has the cdf $x \\mapsto \\frac2\\pi\\, \\mathrm{arcsin}( \\sqrt{x} )$. By differentiation, we can get the associated density: $x \\mapsto \\frac{1}{\\pi \\sqrt{x(1-x)}}$ for all $x\\in (0,1)$. We now check this property with an histogram of the values taken by the Markov chain. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "vmuWCemftXyy",
    "outputId": "fc393775-d3d7-4429-a8c7-3fecd3438c91"
   },
   "outputs": [],
   "source": [
    "m,p=500,10000\n",
    "mc=npr.rand(1)*np.ones(p);\n",
    "f=lambda x: 1/(pi*sqrt(x*(1-x))); \n",
    "x=np.arange(1,m)/m\n",
    "\n",
    "for i in range(p-1):\n",
    "    [a,b]=npr.rand(2)\n",
    "    mc[i+1]=(a<0.5)*b*mc[i]+(a>0.5)*(mc[i]+b*(1-mc[i]))\n",
    "plt.hist(mc,bins=40,density=True,edgecolor=\"black\")\n",
    "plt.plot(x,f(x),color=\"red\")\n",
    "plt.title(\"Histogram of a trajectory of the MC. n=\"+str(p))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba7CAranv6ii"
   },
   "source": [
    "We can also illustrate how the histogram converges to the density of the stationary distribution. This can be done with a dynamical animation with the module \"animation\" from matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "4T0o-IzlwNde",
    "outputId": "2307b33d-0f82-4c88-c8ab-1828027700f3"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "m,p=500,10001\n",
    "mc=npr.rand(1)*np.ones(p)\n",
    "f=lambda x: 1/(pi*sqrt(x*(1-x)))\n",
    "x=np.arange(1,m)/m\n",
    "\n",
    "data = []\n",
    "for i in range(p-1):\n",
    "    [a,b]=npr.rand(2)\n",
    "    mc[i+1]=(a<0.5)*b*mc[i]+(a>0.5)*(mc[i]+b*(1-mc[i]))\n",
    "    \n",
    "    if ((i+1)%100==0):\n",
    "        data.append(list(mc[0:i+1]))\n",
    "\n",
    "\n",
    "number_of_frames =100\n",
    "fig, ax = plt.subplots()\n",
    "plt.close()\n",
    "\n",
    "def update_hist(num,data):\n",
    "    ax.cla()\n",
    "    ax.hist(data[num],bins = 40, density = True, edgecolor = \"black\")\n",
    "    ax.plot(x,f(x),color=\"red\")\n",
    "    ax.set_title(\"Histogram of a trajectory of the MC. sample nb=\"+str((num+1)*100))\n",
    "    \n",
    "anim = animation.FuncAnimation(fig, update_hist, number_of_frames, fargs=(data, ),repeat = False)\n",
    "rc('animation', html='jshtml')\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvQTrUgxialK"
   },
   "source": [
    "We now illustrate the law of large numbers with an example. Take $g(x)=\\pi \\sqrt{x(1-x)}$. Then, we expect that $\\PP-a.s.$, \n",
    "$$\n",
    "\\lim_{n \\to \\infty}n^{-1}\\sum_{i=1}^n g(X_i)=\\pi(g)=\\int_0^1 g(x)  \\frac{1}{\\pi \\sqrt{x(1-x)}}\\rmd x=\\int_0^1 \\rmd x=1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "HXppDnHWkp05",
    "outputId": "ce7beeba-9fcd-4677-d295-1df20893ee0f"
   },
   "outputs": [],
   "source": [
    "p=50000\n",
    "mc=npr.rand(1)*np.ones(p)\n",
    "g=lambda x: (pi*sqrt(x*(1-x)))\n",
    "x=np.arange(1,p+1)/(p)\n",
    "for i in range(p-1):\n",
    "    [a,b]=npr.rand(2)\n",
    "    mc[i+1]=(a<0.5)*b*mc[i]+(a>0.5)*(mc[i]+b*(1-mc[i]))\n",
    "moy=np.cumsum(g(mc))/np.arange(1,p+1)\n",
    "plot(x,moy)\n",
    "plt.ylim([0.6,1.1])\n",
    "axhline(y=1, color='red')\n",
    "labels=[\"empirical means\",\"theoretical value\"]\n",
    "legend(labels)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUCIQn9ETl-R"
   },
   "source": [
    "#### <font color=darkorange> Symmetric Random Walk Metropolis Hasting algorithm </font>\n",
    "\n",
    "We now consider a target distribution which is the mixture of two Gaussian distributions, one centered at $a$ and the other one centered at $-a$ \n",
    "$$\n",
    "\\pi(x)=\\frac{1}{2}\\left(\\phi(x-a)+\\phi(x+a)\\right)=\\frac{1}{2} \\frac{\\rme^{-(x-a)^2}}{\\sqrt{2\\pi}}+\\frac{1}{2} \\frac{\\rme^{-(x+a)^2}}{\\sqrt{2\\pi}}\n",
    "$$\n",
    "where $\\phi$ is the density of the centered standard normal distribution. \n",
    "\n",
    "To target this distribution, we sample according to a Symmetric Random Walk Metropolis Hasting algorithm. When the chain is at the state $X_k$, we propose a candidate $Y_{k+1}$ according to $Y_{k+1}=X_k+Z_k$ where $Z_k\\sim {\\mathcal N}(0,1)$ and then we accept $X_{k+1}=Y_{k+1}$ with probability $\\alpha(X_k,Y_{k+1})$, where $\\alpha(x,y)=\\frac{\\pi(y)}{\\pi(x)} \\wedge 1$. Otherwise, $X_{k+1}=X_{k}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xDS-IcTY0P7-",
    "outputId": "8c3cd777-9b51-46b8-832e-fad714983bb9"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "p,a,r=20001,3,200\n",
    "mc=npr.randn()*np.ones(p)\n",
    "cible=lambda x,a: (np.exp(-(x-a)**2/2)+np.exp(-(x+a)**2/2))/np.sqrt(8*pi)\n",
    "\n",
    "data=[]\n",
    "for i in range(p-1):\n",
    "    v=npr.randn()\n",
    "    alpha=cible(mc[i]+v,a)/cible(mc[i],a)\n",
    "    mc[i+1]=mc[i]\n",
    "    if (npr.rand()<alpha): \n",
    "        mc[i+1] += v        \n",
    "    if ((i+1)%r==0):\n",
    "        data.append(list(mc[0:i]))\n",
    "\n",
    "s=np.cumsum(mc)/np.arange(1,p+1)      \n",
    "x=np.linspace(min(mc),max(mc),100)\n",
    "number_of_frames=int(p/r)\n",
    "fig, ax = plt.subplots(3,1, figsize=(15,9))\n",
    "plt.close()\n",
    "\n",
    "def update_hist(num,data):\n",
    "    fig.tight_layout(rect = [0, 0, 1, 0.9]) \n",
    "    ax[0].cla()\n",
    "    ax[0].set_ylim(0, 0.25)\n",
    "    ax[0].hist(data[num],bins = 40, density = True, edgecolor = \"black\")\n",
    "    ax[0].plot(x,cible(x,a),color=\"red\")\n",
    "    ax[0].plot(mc[num*r],0.005,\"o\",color=\"yellow\")\n",
    "    ax[0].set_title(\"Histogram of a trajectory of the MC. sample nb=\"+str(r*(num+1)))\n",
    "    ax[1].cla()\n",
    "    ax[1].set_xlim(0,p)\n",
    "    ax[1].set_ylim(-6,6)\n",
    "    ax[1].plot(mc[0:num*r])\n",
    "    ax[1].set_title(\"Trajectory of the MC. sample nb=\"+str(r*(num+1)))\n",
    "    ax[2].cla()\n",
    "    ax[2].set_xlim(0,p)\n",
    "    ax[2].set_ylim(-6,6)\n",
    "    ax[2].plot(s[0:num*r])\n",
    "    ax[2].axhline(y=1, color='red')\n",
    "    ax[2].set_title(\"Empirical mean. sample nb=\"+str(r*(num+1)))\n",
    "\n",
    "    \n",
    "anim = animation.FuncAnimation(fig, update_hist, number_of_frames, fargs=(data, ),repeat = False)\n",
    "rc('animation', html='jshtml')\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSGUdjYE6UM9"
   },
   "source": [
    "#### <font color=darkorange> Independent Metropolis Hasting algorithm </font>\n",
    "\n",
    "We again consider a target distribution which is a mixture of two Gaussian distributions, one centered at $a$ and the other one centered at $-a$ \n",
    "$$\n",
    "\\pi(x)=\\frac{1}{2}\\left(\\phi(x-a)+\\phi(x+a)\\right)=\\frac{1}{2} \\frac{\\rme^{-(x-a)^2}}{\\sqrt{2\\pi}}+\\frac{1}{2} \\frac{\\rme^{-(x+a)^2}}{\\sqrt{2\\pi}},\n",
    "$$\n",
    "where $\\phi$ is the density of the centered standard normal distribution. \n",
    "\n",
    "To target this distribution, we sample according to a Metropolis Hasting algorithm with independent proposal. When the chain is at the state $X_k$, we propose a candidate $Y_{k+1}$ according to $Y_{k+1}=Z_k$ where $Z_k\\sim {\\mathcal N}(\\theta,\\sigma^2)$ and then we accept $X_{k+1}=Y_{k+1}$ with probability $\\alpha(X_k,Y_{k+1})$, where $\\alpha(x,y)=\\frac{\\pi(y)q(x)}{\\pi(x)q(y)} \\wedge 1=\\frac{\\pi(y)/q(y)}{\\pi(x)/q(x)} \\wedge 1$ and $q$ is the density of ${\\mathcal N}(\\theta,\\sigma^2)$. Otherwise, $X_{k+1}=X_{k}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8h-UXiS_6Vee",
    "outputId": "56693df2-9935-4b79-fe10-5e0da5f3e84b"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "counts = 0\n",
    "p,a,r,theta,sigma=20001,3,200,2,-4\n",
    "mc=npr.randn()*np.ones(p)\n",
    "cible=lambda x,a: (np.exp(-(x-a)**2/2)+np.exp(-(x+a)**2/2))/np.sqrt(8*pi)\n",
    "densi=lambda x,m,s: np.exp(-(x-m)**2/(2*s**2))/np.sqrt(2*pi*s**2)\n",
    "\n",
    "data=[]\n",
    "for i in range(p-1):\n",
    "    v=sigma*npr.randn()+theta\n",
    "    alpha=cible(v,a)*densi(mc[i],theta,sigma)/(cible(mc[i],a)*densi(v,theta,sigma))\n",
    "    mc[i+1]=mc[i]\n",
    "    if v>6:\n",
    "      counts += 1\n",
    "    if (npr.rand()<alpha): \n",
    "        mc[i+1] = v        \n",
    "    if ((i+1)%r==0):\n",
    "        data.append(list(mc[0:i]))\n",
    "\n",
    "x=np.linspace(min(mc),max(mc),100)\n",
    "maxi=max(cible(x,a)/densi(x,theta,sigma))\n",
    "number_of_frames=int(p/r)\n",
    "fig, ax = plt.subplots(2,1, figsize=(15,9))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "def update_hist(num,data):\n",
    "    fig.tight_layout(rect = [0, 0, 1, 0.9]) \n",
    "    ax[0].cla()\n",
    "    ax[0].plot(mc[num*r],0.005,\"o\",color=\"yellow\")\n",
    "    ax[0].set_ylim(0, 0.25)\n",
    "    ax[0].hist(data[num],bins = 40, density = True, edgecolor = \"black\")\n",
    "    ax[0].plot(x,cible(x,a),color=\"red\")\n",
    "    ax[0].plot(x,densi(x,theta,sigma),color=\"orange\")\n",
    "    ax[0].plot(x,cible(x,a)/densi(x,theta,sigma)*(0.2/maxi),color=\"cyan\")\n",
    "    labels=[\"MC\",\"target\",\"propos.\",\"target/propos.\"]\n",
    "    ax[0].legend(labels)\n",
    "    ax[0].set_title(\"Histogram of a trajectory of the MC. sample nb=\"+str(r*(num+1)))\n",
    "    ax[1].cla()\n",
    "    ax[1].set_xlim(0,p)\n",
    "    ax[1].set_ylim(-6,6)\n",
    "    ax[1].plot(mc[0:num*r], color=\"blue\")\n",
    "    ax[1].set_title(\"Trajectory of the MC. sample nb=\"+str(r*(num+1)))\n",
    "    \n",
    "    \n",
    "anim = animation.FuncAnimation(fig, update_hist, number_of_frames, fargs=(data, ),repeat = False)\n",
    "rc('animation', html='jshtml')\n",
    "anim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
