{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74271289",
   "metadata": {},
   "source": [
    "# TP 14: Predicting dynamics with Neural-ODE\n",
    "\n",
    "\n",
    "**The goal of this pratical is use machine learning models to predict the evolution of dynamical systems driven by physical laws, *e.g.* ordinary Differential Equations (ODE).**\n",
    "\n",
    "Let us considers a physcial system in Newtonian mechanichs composed of a **damped pendulum**, with length $l$ and mass $m$, and $\\theta$ being the angle with respect to the vertical direction:\n",
    "<img src=\"./pendulum.png\" width=\"200\">\n",
    "\n",
    "**Let us denote $\\dot{\\theta_t}:=\\frac{d\\theta}{dt}$ and $\\ddot{\\theta}_t:=\\frac{d^2\\theta}{dt^2}$ as the first and second temporal derivatives of $\\theta$.** The dynamics of the pendulum is driven bt the following ODE on $\\theta$:\n",
    "\n",
    "\n",
    "\\begin{equation} \\ddot{\\theta_t} + \\omega_0^2~ sin\\left(\\theta_t\\right) + \\alpha \\dot{\\theta}_t = 0 \\label{eq1}\\tag{1},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\omega_0 = \\sqrt{\\frac{g}{l}}$ ($g$ is the gravitational constant), and $\\alpha = \\frac{k}{ml^2}$ is the friction coefficient.\n",
    "\n",
    "In the general case, the ODE in Eq (\\ref{eq1}) does not have a closed-form solution. Let us denote as $\\mathbf{Y}_t=(\\theta_t, \\dot{\\theta}_t)$ the 2d state vector of the pendulum. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b0639",
   "metadata": {},
   "source": [
    " **<u>Question 1:</u> show that $\\dot{\\mathbf{Y}_t}=f\\left({\\mathbf{X}_t}\\right)$, *i.e* that the evolution of $\\mathbf{Y}$ follows a first-order ODE. Give the expression of f.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425cdbf",
   "metadata": {},
   "source": [
    "From a given initial condition $\\mathbf{Y}_0=(\\theta_0, \\dot{\\theta}_0)$, we can estimate the state vector $\\mathbf{Y}_t$ at any time $t$: \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{Y}_t = \\mathbf{Y}_0 + \\int_0^t \\dot{\\mathbf{Y}_t} ~dt = \\mathbf{Y}_0 + \\int_0^t f\\left(\\mathbf{Y}_t\\right) dt \\label{eq2}\\tag{2},\n",
    "\\end{equation}\n",
    "\n",
    "where $f\\left( \\mathbf{Y}_t \\right)$ only depends on the current state $\\mathbf{Y}_t$ at time $t$. The integral in Eq (\\ref{eq2}) can be approximated with numerical schemes. The Euler method is simplest one (see figure below): starting from $\\mathbf{Y}_0$, we have $\\mathbf{Y}_{t+1} = \\mathbf{Y}_{t} + f\\left(\\mathbf{Y}_t\\right)$ $\\forall t>1$. The has been extensive studies for developping improved numerical solvers in the last centuries, e.g. different orders of Runge-Kutta solvers.\n",
    "<img src=\"./Euler.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01302bb5",
   "metadata": {},
   "source": [
    "## Part I. Generating damped pendulum simulations\n",
    "First, lets do some import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d19a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, shelve\n",
    "import os\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "from torchdiffeq import odeint_adjoint, odeint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a6673b",
   "metadata": {},
   "source": [
    "### I.a) DampledPendulum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefc731b",
   "metadata": {},
   "source": [
    "**We will write a DampledPendulum Dataset, which simulates different pendulum trajectories from differents initial conditions. Fill the code in the code in the following DampledPendulum class. We use the following setting:** $\\omega_0^2= \\frac{\\Pi}{6}$, $\\alpha= 0.2$, time hoziron : 10, with $dt=0.5$. \n",
    "\n",
    "You have to fill the __init__, __len__ and  __getitem__ functions. For __getitem__, the goal is to simulate a given trajectory from an initial condition: \n",
    "- The function _get_initial_condition is provided\n",
    "- To perform the simulation in __getitem__, you need to: \n",
    "    - Call the _get_initial_condition\n",
    "    - Call the solver: we will use the solve_ivp method from from scipy.integrate, using the 'DOP853' method (Explicit Runge-Kutta method of order 8). \n",
    "- Since the simulation is computationnaly demanding, it can be a good idea to store the states in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DampledPendulum(Dataset):\n",
    "    def __init__(self, num_seq, time_horizon, dt):\n",
    "    \n",
    "        super().__init__()\n",
    "        \n",
    "        self.omega0_square= 0.0 # FILL WITH YOUR CODE\n",
    "        self.alpha= 0.0 # FILL WITH YOUR CODE\n",
    "        \n",
    "        self.len = 0.0 # NUMBER OF SEQUENCES IN DATASET - FILL WITH YOUR CODE\n",
    "        self.time_horizon 0.0 # FILL WITH YOUR CODE\n",
    "        self.dt 0.0 # FILL WITH YOUR CODE\n",
    "        self.data ={} 0.0 # TO STORE THE STATES\n",
    "\n",
    "\n",
    "    def _get_initial_condition(self, seed):\n",
    "        y0 = np.random.randn(2) * 2.0 - 1\n",
    "        r = np.random.rand() + 1.3\n",
    "        y0 = y0 / np.sqrt((y0 ** 2).sum()) * r\n",
    "        \n",
    "        return y0\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        t_eval = torch.from_numpy(np.arange(0, self.time_horizon, self.dt))\n",
    "        \n",
    "        if self.data.get(str(index)) is None:\n",
    "            # GET INITIAL CONDITIONS \n",
    "            y0 = self._get_initial_condition(index)\n",
    "            # PERFORM SIMULATION (i.e. NUMERICAL INTEGRATION) - FILL WITH YOUR CODE  \n",
    "        else:\n",
    "            # LOAD ALREADY COMPUTED STATES - FILL WITH YOUR CODE\n",
    "        \n",
    "        return {'states': states, 't': t_eval.float()}\n",
    "\n",
    "    def __len__(self):\n",
    "        # FILL WITH YOUR CODE\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a380c22e",
   "metadata": {},
   "source": [
    "### I.b) Train/test data generation\n",
    "**We can now define train and test dataloader** (use 25 train/test sequences with a batch size of 25).\n",
    "**Plot the resulting trajectories ($\\theta$ and optionally $\\dot{\\theta}$).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf3ff5c",
   "metadata": {},
   "source": [
    "## 2) Predicting trajectories with Neural-ODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be0785b",
   "metadata": {},
   "source": [
    "**The goal is to use the Neural-ODE method [1] to predict the future trajectory from an initial condition.** As mentionned before, the idea is to define a parametric model to predict the state's derivative from the current state value.\n",
    "\n",
    "**Let's fill the DerivativeEstimator class to predict the the state's derivative.** We will use a simple MLP (2 hiddenn layers + ReLU) for prediction since the state is a 2D vector. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789158d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DerivativeEstimator(nn.Module):\n",
    "    def __init__(self, n_state , n_hidden):\n",
    "        super().__init__()\n",
    "        # FILL WITH YOUR CODE\n",
    "\n",
    "    def forward(self, t, state):\n",
    "        # FILL WITH YOUR CODE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f1b927",
   "metadata": {},
   "source": [
    "**The forecasterwill perform the prediction from a initial state $y_0$**. To perform the numerical integration, we use the 'odeint' method from torchdiffeq. We will use the generic 'rk4' solver to perform numerical integration. **Fill the following  Forecaster class with:** \n",
    "- A constructor creating a reference to an DerivativeEstimator instance \n",
    "- the forward method calls the odeint method to perform integration from an initial $y_0$ state. **N.B.**: the output dimensions after calling odeint will be T x batch_size x n_c, swap them to fit the requested Pytorch standard (batch_size x n_c X T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28919d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Forecaster(nn.Module):\n",
    "    def __init__(self, n_state , n_hidden, method='rk4'):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, y0, t):\n",
    "        # CALL TO ODEINT + DIM SWAP\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a7cc0",
   "metadata": {},
   "source": [
    "### Write the training loop!\n",
    "For each batch: \n",
    "- Get the first state of each training trajectory\n",
    "- Perform prediction of the forecaster for each time step of the horizon\n",
    "- We will use a simple MSE loss between the ground truth and predicted trajectories.\n",
    "- Use an Adam optimizer (default paramters)\n",
    "- Plot the train / test trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc04d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_state = 2\n",
    "n_hidden = 200\n",
    "n_epochs = 1001\n",
    "\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    for iteration,batch in enumerate(train_loader): \n",
    "        # FILL WITH YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b932a8da",
   "metadata": {},
   "source": [
    "# Bonus\n",
    "Experiment Neural ODE for **replacing residual networks with ODEs for supervised learning**: see section 3 in [this paper](https://proceedings.neurips.cc/paper/2018/file/69386f6bb1dfed68692a24c8686939b9-Paper.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d613442",
   "metadata": {},
   "source": [
    "[1] **Neural Ordinary Differential Equations.**\n",
    "Ricky T. Q. Chen, Yulia Rubanova, Jesse Bettencourt, David K. Duvenaud.\n",
    "NeurIPS 2018."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
