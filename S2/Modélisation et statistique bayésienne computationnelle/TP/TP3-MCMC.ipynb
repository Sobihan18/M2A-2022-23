{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLICATION  D'UNE MCMC pour la SIMULATION A POSTERIORI\n",
    "\n",
    "Donnees X (debit de riviere) ~ Loi de GUMBEL (mu,lambda)  \n",
    "A priori sur (mu,lambda) = melange de lois Gamma d'hyperparametres (m, alpha, xe.alpha)  \n",
    "avec :  \n",
    "m = taille d'echantillon fictif (force de l'expertise)  \n",
    "xe_alpha = quantile predictif (sur X, donc positif) a priori de seuil alpha (donne par l'expert)  \n",
    "alpha    = seuil de xe.alpha, compris dans [0,1]  (donne par l'expert)  \n",
    "lambda_e = moyenne a priori de lambda (donnee par l'expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from math import floor\n",
    "from scipy import log, pi, exp, sqrt\n",
    "from scipy import __version__ as sci_version\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import loggamma\n",
    "from numpy.random import normal, uniform, gamma\n",
    "from statistics import mean\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "from statsmodels import __version__ as stm_version\n",
    "from matplotlib import __version__ as mpl_version\n",
    "from pandas import __version__ as pd_version\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy version 1.3.1\n",
      "numpy version 1.16.0\n",
      "matplotlib version 3.1.1\n",
      "statsmodels version 0.11.0\n",
      "pandas version 0.25.3\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "      \"scipy version \" +  sci_version + \n",
    "      \"\\nnumpy version \" + np.__version__ +\n",
    "      \"\\nmatplotlib version \" + mpl_version +\n",
    "      \"\\nstatsmodels version \" + stm_version +\n",
    "      \"\\npandas version \" + pd_version\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeu de donnees \n",
    "\n",
    "30 mesures de débit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ 1306, 1235, 1830, 2442, 1128, 3330, 1530, 3192, 2647, 238,  \n",
    "        706, 1903, 1594,  935, 1100, 2204, 1366, 1629,  522,  642, 1173, \n",
    "        424, 1837, 1391, 789,  383, 1858, 917, 1084, 1026]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1\n",
    "xe_alpha=2000\n",
    "alpha=0.5\n",
    "lambda_e=1/2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Algorithme de Metropolis-Hastings-within-Gibbs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densité a priori sur la moyenne\n",
    "\n",
    "A priori :  \n",
    "$\\lambda \\sim Gamma(m, m/\\lambda_e)$ en paramètrisation $Gamma(shape, rate)$, $rate = 1/scale $  \n",
    "$mu \\sim Gamma(m, b_m(\\lambda))$  en paramètrisation $Gamma(shape, rate)$  \n",
    "avec $b_m(\\lambda) = exp(- \\lambda x_{e,\\alpha}) / (\\alpha^{-1/m} - 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_rate_param(l, m, xe_alpha, alpha) :\n",
    "    \"\"\"\n",
    "        Fonction donnant l'hyperparametre d'echelle de la loi a priori de mu\n",
    "        sachant lambda, m, xe_alpha et alpha\n",
    "    \"\"\"\n",
    "    return exp(- l * xe_alpha) / (alpha ** (- 1 / m) - 1)\n",
    "\n",
    "def sample_from_prior(n, m, xe_alpha, alpha, lambda_e) :\n",
    "    \"\"\"\n",
    "         Simulation de (mu,lambda) a priori\n",
    "    \"\"\"\n",
    "    l = gamma(shape = m, scale = lambda_e / m, size = n)\n",
    "    scale_prior = get_mean_rate_param(l, m, xe_alpha, alpha)\n",
    "    mu = gamma(shape = m, scale = 1 / scale_prior, size = n)\n",
    "    return {\"lambda\" : l, \"mu\" : mu}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-densité a priori sur lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_prior_density(l, lambda_e, m) :\n",
    "    # A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-densite a posteriori de lambda \n",
    "\n",
    "A posteriori :  \n",
    "$\\pi(\\lambda | x_n) = \\gamma(\\lambda) Gamma(m + n , m/\\lambda_e + n\\bar{x}_n)$  \n",
    "avec \n",
    "$\\bar{x}_n = \\frac{1}{n} \\sum_{i=1}^n x_i$,  \n",
    "$\\gamma(\\lambda) \\propto \\frac{b^m_m(\\lambda)}{(b_m(\\lambda) + \\bar{b}_{x_n}(\\lambda))^{m + n}}$  \n",
    "et $\\bar{b}_{x_n} = \\sum_{i = 1}^n exp(-\\lambda x_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_informed_parameters(l, uncensored_data = np.array([]), censored_data = np.array([])) :  \n",
    "    \n",
    "   # A COMPLETER\n",
    "\n",
    "def lambda_log_posterior(l, m, xe_alpha, alpha, lambda_e, uncensored_data, censored_data) :\n",
    "    \n",
    " # A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation conditionnelle de Gibbs de mu sachant lambda a posteriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mu_from_posterior(l, m, xe_alpha, alpha, lambda_e,\n",
    "                           uncensored_data, censored_data) :\n",
    "    \n",
    "    # A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimateurs du maximum de vraisemblance de la loi de Gumbel\n",
    "\n",
    " Estimation rapide des estiamteurs du max de vraisemblance de Gumbel sur des donnees non censurees (via un algorithme de simplexe), utilisés pour initialiser les valeurs de mu et lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_density_Gumbel(data, mu, l) :\n",
    "    return log(l) + log(mu) - l * data - mu * exp(- l* data)\n",
    "\n",
    "def log_likelihood_Gumbel(uncensored_data, censored_data, mu, l) :\n",
    "    \n",
    "    ll = 0\n",
    "    \n",
    "    if uncensored_data.size > 0 :   \n",
    "        ll += np.sum(log_density_Gumbel(uncensored_data, mu, l))\n",
    "\n",
    "    if censored_data.size > 0 :   \n",
    "        ll += np.sum(- mu * exp(- l* censored_data))\n",
    "\n",
    "    return ll\n",
    "\n",
    "\n",
    "def MLE_Gumbel(data, plotting= True) :\n",
    "    \n",
    "    # log-vraisemblance negative a minimiser\n",
    "    # A COMPLETER\n",
    "        \n",
    "    return MLE_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation de lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_lambda(n_chains, data) :\n",
    "    MLE = MLE_Gumbel(data, plotting = False)\n",
    "    return uniform(low = 0, high = 1.5 * MLE[\"lambda\"], size = n_chains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection de la distribution instrumentale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_instrumental_distribution(nb_chains, option, m, xe_alpha, alpha, lambda_e, data) :\n",
    "    \"\"\"\n",
    "        Fonction générant les fonction des log_densite et d'echantillonnage selon l'option selectionnee.\n",
    "    \"\"\"\n",
    "    if option == 1 : \n",
    "        \n",
    "        print(\"Loi instrumentale choisie : loi a priori\\n\")\n",
    "        \n",
    "        def log_density(x,y) :\n",
    "            return m * (log(m) - log(lambda_e)) - loggamma(m) + (m - 1) * log(x) - m * x / lambda_e\n",
    "        \n",
    "        def sampling(n,x) :\n",
    "            sample = gamma(shape = m, scale = lambda_e / m, size = (n * nb_chains))\n",
    "            return np.ndarray(shape =(n,nb_chains), buffer = sample)\n",
    "    \n",
    "    \n",
    "    if option == 2 : \n",
    "        \n",
    "        print(\"Loi instrumentale choisie : loi gamma semblant proche de l'a posteriori sur lambda\\n\")\n",
    "        n = len(data)\n",
    "        xn = np.mean(data)\n",
    "        \n",
    "        def log_density(x,y) :\n",
    "            return (m + n) * log(m / lambda_e + n * xn) - loggamma(m + n) + (m + n - 1) * log(x) - x * (m / lambda_e + n * xn)\n",
    "        \n",
    "        def sampling(n,x) :\n",
    "            sample = gamma(shape = n + m, scale = 1 / (m / lambda_e + n * xn), size = n * nb_chains)\n",
    "            return np.ndarray(shape =(n,nb_chains), buffer = sample)\n",
    "\n",
    "        \n",
    "    if option == 3 :\n",
    "        \n",
    "        print(\"Loi instrumentale choisie : loi normale de moyenne la valeur courante et de coeff. de variation = 5 %\")\n",
    "        coeff_variation = 0.05\n",
    "        \n",
    "        def log_density(x, y) :\n",
    "            sigma = abs(coeff_variation * y)\n",
    "            return -0.5 * log(2 * pi) - log(sigma) - (x-y) ** 2 / (2 * (sigma ** 2))\n",
    "        \n",
    "        def sampling(n, x) :\n",
    "            sigma = abs(coeff_variation * x)\n",
    "            sample = abs(normal(loc = x, scale = sigma, size = n * nb_chains))\n",
    "            return np.ndarray(shape =(n,nb_chains), buffer = sample)\n",
    "    \n",
    "    \n",
    "    if option == 4 :\n",
    "        \n",
    "        print(\"Loi instrumentale choisie : loi normale de moyenne la valeur courante et de coeff. de variation = 25 %\")\n",
    "        coeff_variation = 0.25\n",
    "        \n",
    "        def log_density(x, y) :\n",
    "            sigma = abs(coeff_variation * y)\n",
    "            return -0.5 * log(2 * pi) - log(sigma) - (x-y) ** 2 / (2 * (sigma ** 2))\n",
    "        \n",
    "        def sampling(n, x) :\n",
    "            sigma = abs(coeff_variation * x)\n",
    "            sample = abs(normal(loc = x, scale = sigma, size = n * nb_chains))\n",
    "            return np.ndarray(shape =(n,nb_chains), buffer = sample)\n",
    "        \n",
    "    if option == 5 :\n",
    "        \n",
    "        print(\"Loi instrumentale choisie : loi normale de moyenne la valeur courante et de coeff. de variation = 50 %\")\n",
    "        coeff_variation = 0.5\n",
    "        \n",
    "        def log_density(x, y) :\n",
    "            sigma = abs(coeff_variation * y)\n",
    "            return -0.5 * log(2 * pi) - log(sigma) - (x-y) ** 2 / (2 * (sigma ** 2))\n",
    "        \n",
    "        def sampling(n, x) :\n",
    "            sigma = abs(coeff_variation * x)\n",
    "            sample = abs(normal(loc = x, scale = sigma, size = n * nb_chains))\n",
    "            return np.ndarray(shape =(n,nb_chains), buffer = sample)\n",
    "        \n",
    "    return log_density, sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction de la fonction de densité a posteriori pour lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " def make_log_posterior_density(m, xe_alpha, alpha, lambda_e, uncensored_data, censored_data) :\n",
    "        \n",
    "        def log_posterior_density(l) :\n",
    "            return lambda_log_posterior(l, m, xe_alpha, alpha, lambda_e, uncensored_data, censored_data)\n",
    "        return log_posterior_density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic de l'échantillonnage\n",
    "\n",
    "####                 Statistique de Brooks-Gelman\n",
    "\n",
    "calculee sur un nombre nb_chains de chaines MCMC paralleles pour le parametre theta (matrix Nsim x nb_chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Brooks_Gelman(theta, pro = 0.9) :\n",
    "    \n",
    " # A COMPLETER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Echantillonnage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings_sampling(lambda_old, sampling, log_density, log_posterior_density) :\n",
    "    \n",
    "    # A COMPLETER\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boucle MCMC complète"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings_within_gibbs(data, option = 1, N = 1000, burn_in = 5000, nb_chains = 3,\n",
    "                                     m = 1, xe_alpha = 2000, alpha = 0.5, lambda_e = 1/2000, \n",
    "                                     pause = range(1,101), plotting= range(1, 10)) :\n",
    "    \n",
    "    # A COMPLETER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
